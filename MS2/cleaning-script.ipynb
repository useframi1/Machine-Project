{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Milestone 2 - Cleaning, Processing, and Data Visualization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Include all the necessary imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import requests\n",
    "from datetime import timedelta\n",
    "import openmeteo_requests\n",
    "import requests_cache\n",
    "from retry_requests import retry\n",
    "from fitter import Fitter, get_common_distributions, get_distributions\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from distfit import distfit\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the csv into a pandas dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Flight_delay.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"cleaned_df_with_weather.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the df info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the head of the df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning and Processing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop rows with null values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to create a column in the dataframe called 'ScheduledDepTime', which has the scheduled departure time of each flight in the dataset.\n",
    "\n",
    "This computed by subtracting the departure delay (in minutes) from the actual departure time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_scheduled_dep_time_col():\n",
    "    # Convert 'DepTime' to string type\n",
    "    df[\"DepTime\"] = df[\"DepTime\"].astype(str)\n",
    "\n",
    "    # Pad 'DepTime' with leading zeros to ensure it has 4 digits\n",
    "    df[\"DepTime\"] = df[\"DepTime\"].str.zfill(4)\n",
    "\n",
    "    # Replace '2400' with '0000' in 'DepTime'\n",
    "    df[\"DepTime\"] = df[\"DepTime\"].replace(\"2400\", \"0000\")\n",
    "\n",
    "    # Convert 'DepTime' column to datetime format\n",
    "    df[\"DepTime\"] = pd.to_datetime(df[\"DepTime\"], format=\"%H%M\")\n",
    "\n",
    "    # Subtract 'DepDelay' from 'DepTime'\n",
    "    df[\"ScheduledDepTime\"] = df.apply(\n",
    "        lambda row: row[\"DepTime\"] - timedelta(minutes=row[\"DepDelay\"]), axis=1\n",
    "    )\n",
    "\n",
    "    # Convert 'ScheduledDepTime' back to the original format\n",
    "    df[\"ScheduledDepTime\"] = df[\"ScheduledDepTime\"].dt.strftime(\"%H%M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to recompute the scheduled elpased time of each flight.\n",
    "\n",
    "This is computed by subtracting the scheduled departure time from the scheduled arrival time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsert_scheduled_elapsed_time():\n",
    "    # Rename the 'CRSArrTime' column to 'ScheduledArrTime'\n",
    "    df.rename(columns={\"CRSArrTime\": \"ScheduledArrTime\"}, inplace=True)\n",
    "\n",
    "    # Convert columns to string type\n",
    "    df[\"ScheduledArrTime\"] = df[\"ScheduledArrTime\"].astype(str)\n",
    "    df[\"ScheduledDepTime\"] = df[\"ScheduledDepTime\"].astype(str)\n",
    "\n",
    "    # Pad columns with leading zeros to ensure it has 4 digits\n",
    "    df[\"ScheduledArrTime\"] = df[\"ScheduledArrTime\"].str.zfill(4)\n",
    "    df[\"ScheduledDepTime\"] = df[\"ScheduledDepTime\"].str.zfill(4)\n",
    "\n",
    "    # Replace '2400' with '0000' in columns\n",
    "    df[\"ScheduledArrTime\"] = df[\"ScheduledArrTime\"].replace(\"2400\", \"0000\")\n",
    "    df[\"ScheduledDepTime\"] = df[\"ScheduledDepTime\"].replace(\"2400\", \"0000\")\n",
    "\n",
    "    # Convert columns to datetime format\n",
    "    df[\"ScheduledArrTime\"] = pd.to_datetime(df[\"ScheduledArrTime\"], format=\"%H%M\")\n",
    "    df[\"ScheduledDepTime\"] = pd.to_datetime(df[\"ScheduledDepTime\"], format=\"%H%M\")\n",
    "\n",
    "    # Calculate the scheduled elapsed time and create a new column 'ScheduledElapsedTime'\n",
    "    df[\"ScheduledElapsedTime\"] = (\n",
    "        (\n",
    "            df[\"ScheduledArrTime\"] - df[\"ScheduledDepTime\"] + pd.Timedelta(days=1)\n",
    "        ).dt.total_seconds()\n",
    "        / 60\n",
    "    ).astype(int)\n",
    "\n",
    "    # Use modulo operation to limit the elapsed time within 24 hours\n",
    "    df[\"ScheduledElapsedTime\"] = df[\"ScheduledElapsedTime\"] % (24 * 60)\n",
    "\n",
    "    # Convert 'ScheduledArrTime' and 'ScheduledDepTime' back to the original format\n",
    "    df[\"ScheduledArrTime\"] = df[\"ScheduledArrTime\"].dt.strftime(\"%H%M\")\n",
    "    df[\"ScheduledDepTime\"] = df[\"ScheduledDepTime\"].dt.strftime(\"%H%M\")\n",
    "\n",
    "    # Convert 'ScheduledArrTime' and 'ScheduledDepTime' to int\n",
    "    df[\"ScheduledArrTime\"] = df[\"ScheduledArrTime\"].astype(int)\n",
    "    df[\"ScheduledDepTime\"] = df[\"ScheduledDepTime\"].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to expand the 'Date' column to a 'Day' and 'Month' columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_date_col():\n",
    "    # Convert the date column to datetime\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"Date\"], format=\"%d-%m-%Y\")\n",
    "\n",
    "    # Create the Day, Month and Year columns\n",
    "    df[\"Day\"] = df[\"Date\"].dt.day\n",
    "    df[\"Month\"] = df[\"Date\"].dt.month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to call the google geocode API to retrieve the lat and long of the airports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geocode(address):\n",
    "    url = \"https://maps.googleapis.com/maps/api/geocode/json\"\n",
    "    params = {\"address\": address, \"key\": \"AIzaSyCeWJLbBvTsN3WoA7R8y4M3DzGkKQHJp80\"}\n",
    "    response = requests.get(url, params=params)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        if \"results\" in data and len(data[\"results\"]) > 0:\n",
    "            location = data[\"results\"][0][\"geometry\"][\"location\"]\n",
    "            return location[\"lat\"], location[\"lng\"]\n",
    "    return None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to call an API to get weather conditions for a certain lat and long, start and end dates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weather_conditions(lat, long, start_date, end_date):\n",
    "    # Setup the Open-Meteo API client with cache and retry on error\n",
    "    cache_session = requests_cache.CachedSession(\".cache\", expire_after=-1)\n",
    "    retry_session = retry(cache_session, retries=5, backoff_factor=0.2)\n",
    "    openmeteo = openmeteo_requests.Client(session=retry_session)\n",
    "\n",
    "    # Make sure all required weather variables are listed here\n",
    "    # The order of variables in hourly or daily is important to assign them correctly below\n",
    "    url = \"https://archive-api.open-meteo.com/v1/archive\"\n",
    "    params = {\n",
    "        \"latitude\": lat,\n",
    "        \"longitude\": long,\n",
    "        \"start_date\": start_date,\n",
    "        \"end_date\": end_date,\n",
    "        \"hourly\": [\n",
    "            \"temperature_2m\",\n",
    "            \"precipitation\",\n",
    "            \"rain\",\n",
    "            \"snowfall\",\n",
    "            \"wind_speed_10m\",\n",
    "            \"wind_direction_10m\",\n",
    "        ],\n",
    "    }\n",
    "    responses = openmeteo.weather_api(url, params=params)\n",
    "\n",
    "    # Process hourly data. The order of variables needs to be the same as requested.\n",
    "    hourly = responses[0].Hourly()\n",
    "    hourly_temperature_2m = hourly.Variables(0).ValuesAsNumpy()  # type:ignore\n",
    "    hourly_precipitation = hourly.Variables(1).ValuesAsNumpy()  # type:ignore\n",
    "    hourly_rain = hourly.Variables(2).ValuesAsNumpy()  # type:ignore\n",
    "    hourly_snowfall = hourly.Variables(3).ValuesAsNumpy()  # type:ignore\n",
    "    hourly_wind_speed_10m = hourly.Variables(4).ValuesAsNumpy()  # type:ignore\n",
    "    hourly_wind_direction_10m = hourly.Variables(5).ValuesAsNumpy()  # type:ignore\n",
    "\n",
    "    hourly_data = {\n",
    "        \"date\": pd.date_range(\n",
    "            start=pd.to_datetime(hourly.Time(), unit=\"s\", utc=True),  # type: ignore\n",
    "            end=pd.to_datetime(hourly.TimeEnd(), unit=\"s\", utc=True),  # type: ignore\n",
    "            freq=pd.Timedelta(seconds=hourly.Interval()),  # type: ignore\n",
    "            inclusive=\"left\",\n",
    "        )\n",
    "    }\n",
    "    hourly_data[\"Temperature\"] = hourly_temperature_2m  # type:ignore\n",
    "    hourly_data[\"Precipitation\"] = hourly_precipitation  # type:ignore\n",
    "    hourly_data[\"Rain\"] = hourly_rain  # type:ignore\n",
    "    hourly_data[\"SnowFall\"] = hourly_snowfall  # type:ignore\n",
    "    hourly_data[\"WindSpeed\"] = hourly_wind_speed_10m  # type:ignore\n",
    "    hourly_data[\"WindDirection\"] = hourly_wind_direction_10m  # type:ignore\n",
    "\n",
    "    return pd.DataFrame(data=hourly_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to correct airport names so that the google API could get their coordinates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_airport_names():\n",
    "    df[\"Org_Airport\"] = df[\"Org_Airport\"].replace(\n",
    "        {\n",
    "            \"Rogue Valley International Airport\": \"Rogue Valley International Medford Airport\"\n",
    "        }\n",
    "    )\n",
    "    df[\"Org_Airport\"] = df[\"Org_Airport\"].replace(\n",
    "        {\n",
    "            \"Gen. Edward Lawrence Logan International Airport\": \"Boston Logan International Airport\"\n",
    "        }\n",
    "    )\n",
    "\n",
    "    df[\"Dest_Airport\"] = df[\"Dest_Airport\"].replace(\n",
    "        {\n",
    "            \"Rogue Valley International Airport\": \"Rogue Valley International Medford Airport\"\n",
    "        }\n",
    "    )\n",
    "    df[\"Dest_Airport\"] = df[\"Dest_Airport\"].replace(\n",
    "        {\n",
    "            \"Gen. Edward Lawrence Logan International Airport\": \"Boston Logan International Airport\"\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to insert the weather conditions columns for departure and arrival\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_weather_conditions_cols():\n",
    "    weather_columns = [\n",
    "        \"Temperature\",\n",
    "        \"WindSpeed\",\n",
    "        \"WindDirection\",\n",
    "        \"Precipitation\",\n",
    "        \"Rain\",\n",
    "        \"SnowFall\",\n",
    "    ]\n",
    "    for prefix in [\"Dep\", \"Arr\"]:\n",
    "        for column in weather_columns:\n",
    "            df[f\"{prefix}{column}\"] = None\n",
    "    return weather_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to create a dictionary having all the unique airports as keys and empty dataframes as values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_locations_dict(unique_locations):\n",
    "    locations_dict = {value: pd.DataFrame() for value in unique_locations}\n",
    "    for i in range(len(unique_locations)):\n",
    "        print(i)\n",
    "        print(unique_locations[i])\n",
    "        lat, long = geocode(unique_locations[i])\n",
    "\n",
    "        print(\"lat: \" + str(lat))\n",
    "        print(\"long: \" + str(long))\n",
    "        print()\n",
    "        if lat != None and long != None:\n",
    "            locations_dict[unique_locations[i]] = get_weather_conditions(\n",
    "                lat, long, \"2019-01-01\", \"2019-06-30\"\n",
    "            )\n",
    "    return locations_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to add the weather conditions to the df according to the location and datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_weather_condtions(locations_dict, weather_columns):\n",
    "    j = 0\n",
    "    for index, row in df.iterrows():\n",
    "        if (\n",
    "            not locations_dict[row[\"Org_Airport\"]].empty\n",
    "            and not locations_dict[row[\"Dest_Airport\"]].empty\n",
    "        ):\n",
    "            print(j)\n",
    "            # Create temporary DataFrames for the operation\n",
    "            df_row = pd.DataFrame(row).transpose().copy()\n",
    "            dep_df = locations_dict[row[\"Org_Airport\"]].copy()\n",
    "            arr_df = locations_dict[row[\"Dest_Airport\"]].copy()\n",
    "\n",
    "            df_row[\"ScheduledDepTime\"] = df_row[\"ScheduledDepTime\"].astype(str)\n",
    "            df_row[\"ScheduledDepTime\"] = df_row[\"ScheduledDepTime\"].str.zfill(4)\n",
    "\n",
    "            df_row[\"ScheduledArrTime\"] = df_row[\"ScheduledArrTime\"].astype(str)\n",
    "            df_row[\"ScheduledArrTime\"] = df_row[\"ScheduledArrTime\"].str.zfill(4)\n",
    "\n",
    "            df_row[\"ScheduledDepTime\"] = pd.to_timedelta(\n",
    "                str(df_row[\"ScheduledDepTime\"].values[0])[:2]\n",
    "                + \":\"\n",
    "                + str(df_row[\"ScheduledDepTime\"].values[0])[2:]\n",
    "                + \":00\"\n",
    "            )\n",
    "            df_row[\"ScheduledArrTime\"] = pd.to_timedelta(\n",
    "                str(df_row[\"ScheduledArrTime\"].values[0])[:2]\n",
    "                + \":\"\n",
    "                + str(df_row[\"ScheduledArrTime\"].values[0])[2:]\n",
    "                + \":00\"\n",
    "            )\n",
    "\n",
    "            df_row[\"DepDateTime\"] = df_row[\"Date\"] + df_row[\"ScheduledDepTime\"]\n",
    "            df_row[\"ArrDateTime\"] = df_row[\"Date\"] + df_row[\"ScheduledArrTime\"]\n",
    "\n",
    "            # Convert 'date' column in df2 to datetime format without timezone\n",
    "            dep_df[\"date\"] = dep_df[\"date\"].dt.tz_convert(None)\n",
    "            arr_df[\"date\"] = arr_df[\"date\"].dt.tz_convert(None)\n",
    "\n",
    "            # # Extract date and hour from 'DateTime' in df1 and 'date' in df2\n",
    "            df_row[\"DepDateTime\"] = pd.to_datetime(df_row[\"DepDateTime\"]).dt.floor(\"h\")\n",
    "            df_row[\"ArrDateTime\"] = pd.to_datetime(df_row[\"ArrDateTime\"]).dt.floor(\"h\")\n",
    "            dep_df[\"date\"] = dep_df[\"date\"].dt.floor(\"h\")\n",
    "            arr_df[\"date\"] = arr_df[\"date\"].dt.floor(\"h\")\n",
    "\n",
    "            # # Merge the two DataFrames on the datetime column\n",
    "            dep_weather = pd.merge(\n",
    "                df_row, dep_df, left_on=\"DepDateTime\", right_on=\"date\"\n",
    "            )\n",
    "            arr_weather = pd.merge(\n",
    "                df_row, arr_df, left_on=\"ArrDateTime\", right_on=\"date\"\n",
    "            )\n",
    "\n",
    "            # # Drop the temporary columns\n",
    "            dep_weather = dep_weather.drop(columns=[\"DepDateTime\", \"date\"])\n",
    "            arr_weather = arr_weather.drop(columns=[\"ArrDateTime\", \"date\"])\n",
    "\n",
    "            for column in weather_columns:\n",
    "                df.at[index, f\"Dep{column}\"] = dep_weather[column][0]\n",
    "                df.at[index, f\"Arr{column}\"] = arr_weather[column][0]\n",
    "\n",
    "            j += 1\n",
    "        else:\n",
    "            for column in weather_columns:\n",
    "                df.at[index, f\"Dep{column}\"] = 0\n",
    "                df.at[index, f\"Arr{column}\"] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to insert and fill the weather conditions columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_weather_conditons_cols():\n",
    "    correct_airport_names()\n",
    "\n",
    "    unique_locations = (\n",
    "        pd.concat([df[\"Org_Airport\"], df[\"Dest_Airport\"]]).unique().tolist()\n",
    "    )\n",
    "\n",
    "    # Create new columns in the DataFrame for weather conditions\n",
    "    weather_columns = insert_weather_conditions_cols()\n",
    "\n",
    "    # Create a dictionary with unique locations as keys and empty DataFrames as values\n",
    "    print(\"######### CREATING LOCATIONS DICTIONARY #########\")\n",
    "    locations_dict = create_locations_dict(unique_locations)\n",
    "\n",
    "    # Match the weather conditions with the departure and arrival times\n",
    "    print(\"######### GETTING WEATHER CONDITIONS #########\")\n",
    "    add_weather_condtions(locations_dict, weather_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_scheduled_dep_time_col()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "upsert_scheduled_elapsed_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "expand_date_col()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_weather_conditons_cols()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop the unecessary columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\n",
    "    columns=[\n",
    "        \"ArrTime\",\n",
    "        \"Airline\",\n",
    "        \"FlightNum\",\n",
    "        \"ActualElapsedTime\",\n",
    "        \"AirTime\",\n",
    "        \"ArrDelay\",\n",
    "        \"Org_Airport\",\n",
    "        \"Dest_Airport\",\n",
    "        \"TaxiIn\",\n",
    "        \"TaxiOut\",\n",
    "        \"Cancelled\",\n",
    "        \"CancellationCode\",\n",
    "        \"Diverted\",\n",
    "        \"CarrierDelay\",\n",
    "        \"WeatherDelay\",\n",
    "        \"NASDelay\",\n",
    "        \"LateAircraftDelay\",\n",
    "        \"SecurityDelay\",\n",
    "        \"Date\",\n",
    "        \"DepTime\",\n",
    "        \"CRSElapsedTime\",\n",
    "    ],\n",
    "    inplace=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the features and the label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_NAME = \"DepDelay\"\n",
    "LABEL_COL = df[LABEL_NAME]\n",
    "\n",
    "FEATURES_NAMES = [col for col in df.columns if col != LABEL_NAME]\n",
    "FEATURES_COLS = df[FEATURES_NAMES]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the cleaned df into another csv file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"cleaned_df_with_weather.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the df info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the head of the df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>ScheduledArrTime</th>\n",
       "      <th>UniqueCarrier</th>\n",
       "      <th>TailNum</th>\n",
       "      <th>DepDelay</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Dest</th>\n",
       "      <th>Distance</th>\n",
       "      <th>ScheduledDepTime</th>\n",
       "      <th>ScheduledElapsedTime</th>\n",
       "      <th>Day</th>\n",
       "      <th>Month</th>\n",
       "      <th>DepTemperature</th>\n",
       "      <th>DepWindSpeed</th>\n",
       "      <th>DepWindDirection</th>\n",
       "      <th>DepPrecipitation</th>\n",
       "      <th>DepRain</th>\n",
       "      <th>DepSnowFall</th>\n",
       "      <th>ArrTemperature</th>\n",
       "      <th>ArrWindSpeed</th>\n",
       "      <th>ArrWindDirection</th>\n",
       "      <th>ArrPrecipitation</th>\n",
       "      <th>ArrRain</th>\n",
       "      <th>ArrSnowFall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>1925</td>\n",
       "      <td>WN</td>\n",
       "      <td>N464WN</td>\n",
       "      <td>34</td>\n",
       "      <td>IND</td>\n",
       "      <td>BWI</td>\n",
       "      <td>515</td>\n",
       "      <td>1755</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2.072</td>\n",
       "      <td>8.913181</td>\n",
       "      <td>226.636536</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.022</td>\n",
       "      <td>16.641972</td>\n",
       "      <td>308.853394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>1940</td>\n",
       "      <td>WN</td>\n",
       "      <td>N763SW</td>\n",
       "      <td>67</td>\n",
       "      <td>IND</td>\n",
       "      <td>LAS</td>\n",
       "      <td>1591</td>\n",
       "      <td>1830</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3.522</td>\n",
       "      <td>8.496305</td>\n",
       "      <td>233.615555</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.8325</td>\n",
       "      <td>2.595997</td>\n",
       "      <td>303.690094</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>1725</td>\n",
       "      <td>WN</td>\n",
       "      <td>N334SW</td>\n",
       "      <td>94</td>\n",
       "      <td>IND</td>\n",
       "      <td>MCO</td>\n",
       "      <td>828</td>\n",
       "      <td>1510</td>\n",
       "      <td>135</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.078</td>\n",
       "      <td>8.217153</td>\n",
       "      <td>208.810699</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.963001</td>\n",
       "      <td>11.119281</td>\n",
       "      <td>209.054504</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1625</td>\n",
       "      <td>WN</td>\n",
       "      <td>N286WN</td>\n",
       "      <td>27</td>\n",
       "      <td>IND</td>\n",
       "      <td>PHX</td>\n",
       "      <td>1489</td>\n",
       "      <td>1425</td>\n",
       "      <td>120</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.878</td>\n",
       "      <td>6.193674</td>\n",
       "      <td>215.537766</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.878</td>\n",
       "      <td>9.449572</td>\n",
       "      <td>107.744766</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1510</td>\n",
       "      <td>WN</td>\n",
       "      <td>N674AA</td>\n",
       "      <td>28</td>\n",
       "      <td>IND</td>\n",
       "      <td>TPA</td>\n",
       "      <td>838</td>\n",
       "      <td>1255</td>\n",
       "      <td>135</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-4.178</td>\n",
       "      <td>6.162207</td>\n",
       "      <td>263.290253</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.687</td>\n",
       "      <td>9.255571</td>\n",
       "      <td>193.495743</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DayOfWeek  ScheduledArrTime UniqueCarrier TailNum  DepDelay Origin Dest  \\\n",
       "0          4              1925            WN  N464WN        34    IND  BWI   \n",
       "1          4              1940            WN  N763SW        67    IND  LAS   \n",
       "2          4              1725            WN  N334SW        94    IND  MCO   \n",
       "3          4              1625            WN  N286WN        27    IND  PHX   \n",
       "4          4              1510            WN  N674AA        28    IND  TPA   \n",
       "\n",
       "   Distance  ScheduledDepTime  ScheduledElapsedTime  Day  Month  \\\n",
       "0       515              1755                    90    3      1   \n",
       "1      1591              1830                    70    3      1   \n",
       "2       828              1510                   135    3      1   \n",
       "3      1489              1425                   120    3      1   \n",
       "4       838              1255                   135    3      1   \n",
       "\n",
       "  DepTemperature DepWindSpeed DepWindDirection DepPrecipitation DepRain  \\\n",
       "0          2.072     8.913181       226.636536              0.0     0.0   \n",
       "1          3.522     8.496305       233.615555              0.0     0.0   \n",
       "2         -1.078     8.217153       208.810699              0.0     0.0   \n",
       "3         -2.878     6.193674       215.537766              0.0     0.0   \n",
       "4         -4.178     6.162207       263.290253              0.0     0.0   \n",
       "\n",
       "  DepSnowFall ArrTemperature ArrWindSpeed ArrWindDirection ArrPrecipitation  \\\n",
       "0         0.0          8.022    16.641972       308.853394              0.0   \n",
       "1         0.0         5.8325     2.595997       303.690094              0.0   \n",
       "2         0.0      25.963001    11.119281       209.054504              0.2   \n",
       "3         0.0          1.878     9.449572       107.744766              0.0   \n",
       "4         0.0         22.687     9.255571       193.495743              0.4   \n",
       "\n",
       "  ArrRain ArrSnowFall  \n",
       "0     0.0         0.0  \n",
       "1     0.0         0.0  \n",
       "2     0.2         0.0  \n",
       "3     0.0         0.0  \n",
       "4     0.4         0.0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Satistics and Visualization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to normalize the data based on different methods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data, method):\n",
    "    if method == \"min-max\":\n",
    "        return MinMaxScaler().fit_transform(data)\n",
    "    elif method == \"z-score\":\n",
    "        return StandardScaler().fit_transform(data)\n",
    "    elif method == \"log\":\n",
    "        return np.log(np.abs(data.flatten()) + 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Best Fitting Distribution and Normalization Method\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column = \"DepDelay\"\n",
    "data = np.array(df[column].values).reshape(-1, 1)\n",
    "\n",
    "normalization_methods = [\"z-score\", \"min-max\", \"log\"]\n",
    "best_normalization_method = \"\"\n",
    "best_fitted_dist = \"\"\n",
    "best_sse = np.Inf\n",
    "\n",
    "for method in normalization_methods:\n",
    "    print(\"##### \" + method + \"#####\")\n",
    "    normalized_data = normalize(data=data, method=method)\n",
    "    f = Fitter(normalized_data, distributions=get_common_distributions())\n",
    "    f.fit()\n",
    "    sse = f.summary(plot=False).sort_values(by=[\"sumsquare_error\"]).iloc[0, 0]\n",
    "    if sse < best_sse:  # type:ignore\n",
    "        best_sse = sse\n",
    "        dist = f.get_best(method=\"sumsquare_error\")\n",
    "        best_dist = \"\"\n",
    "        for key in dist.keys():\n",
    "            best_dist = key\n",
    "        best_fitted_dist = best_dist\n",
    "        best_normalization_method = method\n",
    "\n",
    "print(f\"Best SSE: {best_sse}\")\n",
    "print(f\"Best Distribution: {best_dist}\")\n",
    "print(f\"Best Normalization Method: {best_normalization_method}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column = \"DepDelay\"\n",
    "data = np.array(df[column].values).reshape(-1, 1)\n",
    "\n",
    "normalization_methods = [\"z-score\", \"min-max\", \"log\"]\n",
    "best_normalization_method = \"\"\n",
    "best_fitted_dist = \"\"\n",
    "best_score = np.Inf\n",
    "\n",
    "for method in normalization_methods:\n",
    "    print(\"##### \" + method + \"#####\")\n",
    "    normalized_data = normalize(data=data, method=method)\n",
    "    dist = distfit()\n",
    "    dist.fit_transform(normalized_data)\n",
    "    best_dist = dist.summary.sort_values(by=[\"score\"])  # type:ignore\n",
    "    score = best_dist.iloc[0, 1]\n",
    "    if score < best_score:  # type:ignore\n",
    "        best_score = score\n",
    "        best_fitted_dist = best_dist.iloc[0, 0]\n",
    "        best_normalization_method = method\n",
    "\n",
    "print(f\"Best score: {best_score}\")\n",
    "print(f\"Best Distribution: {best_fitted_dist}\")\n",
    "print(f\"Best Normalization Method: {best_normalization_method}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the distribution of each column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df.columns:\n",
    "    sns.displot(data=df, x=column, bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make scatter plots for each column against the 'DepDelay' column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increase the width of the figure\n",
    "fig, axes = plt.subplots(\n",
    "    nrows=len(FEATURES_NAMES), ncols=1, figsize=(5, len(FEATURES_NAMES) * 5)\n",
    ")\n",
    "\n",
    "for i in range(0, len(FEATURES_NAMES)):\n",
    "    axes[i].scatter(FEATURES_COLS[FEATURES_NAMES[i]], LABEL_COL)\n",
    "    axes[i].set_title(f\"{LABEL_NAME} vs {FEATURES_NAMES[i]}\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out the correlations between the 'DepDelay' column and all the other columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only numeric columns\n",
    "numeric_features = FEATURES_COLS.select_dtypes(exclude=[\"object\"])\n",
    "\n",
    "# Calculate the correlation of the label column with the other numeric columns\n",
    "correlation = numeric_features.corrwith(LABEL_COL).to_frame(\"Correlation with DepDelay\")\n",
    "correlation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
